import os
import time
import torch
from torch_geometric.loader import DataLoader
from torch.utils.tensorboard import SummaryWriter  # ç”¨äºæ—¥å¿—è®°å½•ï¼ˆæ›¿ä»£ Lightning æ—¥å¿—ï¼‰

# å¯¼å…¥NPUç›¸å…³ä¾èµ–ï¼ˆè‹¥æœªå®‰è£…éœ€å…ˆæ‰§è¡Œï¼špip install torch-npuï¼‰
try:
    import torch_npu
except ImportError:
    raise ImportError("è¯·å…ˆå®‰è£…torch-npuä»¥æ”¯æŒNPUè®¾å¤‡ï¼Œå®‰è£…å‘½ä»¤ï¼špip install torch-npu")

# å¯¼å…¥çº¯PyTorchç‰ˆæ¨¡å‹ï¼ˆæ›¿æ¢åŸ Lightning ç‰ˆ GAE_GIN_lightningï¼‰
from unsupervised_train.model import GAE_GIN  # éœ€ç¡®ä¿ model.py ä¸­æ˜¯ä¿®æ”¹åçš„çº¯PyTorchç‰ˆ
from unsupervised_train.dataloader import GraphDataset


def main():
    # 1. åŸºç¡€é…ç½®ï¼ˆä¸åŸä»£ç ä¸€è‡´ï¼‰
    data_dir = "../data/graph_dataset"  # å›¾æ•°æ®ç›®å½•ï¼ˆ.ptæ–‡ä»¶ï¼‰
    batch_size = 8  # æ‰¹å¤§å°
    num_workers = 4  # æ•°æ®åŠ è½½è¿›ç¨‹æ•°
    target_npu = "npu:6"  # ç›®æ ‡NPUå¡å·ï¼ˆå¯æ ¹æ®éœ€æ±‚ä¿®æ”¹ï¼‰
    max_epochs = 20  # è®­ç»ƒè½®æ¬¡
    checkpoint_dir = "./checkpoints"  # æƒé‡ä¿å­˜ç›®å½•
    log_dir = os.path.join(checkpoint_dir, "logs")  # æ—¥å¿—ä¿å­˜ç›®å½•
    best_model_path = os.path.join(checkpoint_dir, "best", "gin-unsupervised-best.pth")  # æœ€ä¼˜æƒé‡è·¯å¾„

    # 2. è®¾å¤‡æ£€æµ‹ä¸é…ç½®ï¼ˆä¿ç•™åŸNPUä¼˜å…ˆé€»è¾‘ï¼‰
    # æ£€æŸ¥NPUæ˜¯å¦å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨æŒ‡å®šçš„NPUï¼Œå¦åˆ™é™çº§åˆ°GPU/CPU
    npu_available = torch.npu.is_available() and target_npu in [f"npu:{i}" for i in range(torch.npu.device_count())]
    if npu_available:
        device = torch.device(target_npu)
        torch.npu.set_device(device)  # è®¾ç½®é»˜è®¤NPUè®¾å¤‡
        print(f"âœ… æ£€æµ‹åˆ°å¯ç”¨NPUè®¾å¤‡ï¼š{target_npu}ï¼Œå°†ä½¿ç”¨è¯¥è®¾å¤‡è®­ç»ƒ")
    else:
        # è‹¥NPUä¸å¯ç”¨ï¼Œé™çº§åˆ°GPU/CPU
        if torch.cuda.is_available():
            device = torch.device("cuda:0")
            print(f"âš ï¸ æŒ‡å®šçš„NPUè®¾å¤‡{target_npu}ä¸å¯ç”¨ï¼Œé™çº§ä½¿ç”¨GPU:0")
        else:
            device = torch.device("cpu")
            print(f"âš ï¸ NPUå’ŒGPUå‡ä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒï¼ˆè®­ç»ƒé€Ÿåº¦å¯èƒ½è¾ƒæ…¢ï¼‰")

    # 3. ç›®å½•åˆ›å»ºï¼ˆç¡®ä¿æ—¥å¿—å’Œæƒé‡ç›®å½•å­˜åœ¨ï¼‰
    os.makedirs(os.path.join(checkpoint_dir, "best"), exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)
    # åˆå§‹åŒ–TensorBoardæ—¥å¿—ï¼ˆæ›¿ä»£ Lightning çš„æ—¥å¿—åŠŸèƒ½ï¼‰
    writer = SummaryWriter(log_dir=log_dir)

    # 4. æ•°æ®åŠ è½½ï¼ˆä¸åŸä»£ç ä¸€è‡´ï¼Œä¿ç•™pin_memoryåŠ é€Ÿï¼‰
    # åŠ è½½å›¾æ•°æ®é›†ï¼Œè‡ªåŠ¨è¯»å–ç›®å½•ä¸‹æ‰€æœ‰.ptæ–‡ä»¶
    train_dataset = GraphDataset(data_dir)
    # æ„å»ºDataLoaderï¼Œæ‰¹é‡åŠ è½½æ•°æ®ï¼ˆshuffle=Trueæ‰“ä¹±è®­ç»ƒæ•°æ®ï¼‰
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True  # å¼€å¯å†…å­˜é”å®šï¼ŒåŠ é€Ÿæ•°æ®ä¼ è¾“åˆ°NPU/GPU
    )
    print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®é›†ï¼šå…±{len(train_dataset)}ä¸ªå›¾æ ·æœ¬ï¼Œæ‰¹å¤§å°={batch_size}")

    # 5. æ¨¡å‹åˆå§‹åŒ–ï¼ˆæ›¿æ¢ä¸ºçº¯PyTorchç‰ˆ GAE_GINï¼‰
    model = GAE_GIN(
        in_channels=768,  # é‡ç‚¹ï¼šå¿…é¡»ä¸data.xçš„ç»´åº¦ä¸€è‡´ï¼ˆåŸä»£ç 128éœ€æ ¹æ®å®é™…æ•°æ®ä¿®æ”¹ï¼‰
        out_channels=768,  # ä¿ç•™æ¥å£å…¼å®¹æ€§ï¼Œæ— å®é™…ä½œç”¨
        device=device,  # ä¼ å…¥æŒ‡å®šè®¾å¤‡ï¼ˆNPU/GPU/CPUï¼‰
        encoder_kwargs={
            "num_gc_layers": 2,  # GINå±‚æ•°ï¼ˆå¯è°ƒæ•´ï¼‰
            "hidden_dim": 128  # GINæ¯å±‚è¾“å‡ºç»´åº¦ï¼ˆå¯è°ƒæ•´ï¼‰
        }
    )
    print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œå·²åŠ è½½åˆ°{device}è®¾å¤‡")

    # 6. ä¼˜åŒ–å™¨ä¸è®­ç»ƒé…ç½®ï¼ˆæ›¿ä»£ Lightning çš„ Trainer å’Œ configure_optimizersï¼‰
    optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)  # ä¸åŸLightningå­¦ä¹ ç‡ä¸€è‡´
    best_train_loss = float("inf")  # è®°å½•æœ€ä¼˜æŸå¤±ï¼ˆç”¨äºä¿å­˜æœ€ä¼˜æƒé‡ï¼‰
    log_every_n_steps = 10  # æ¯10æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—ï¼ˆä¸åŸLightningä¸€è‡´ï¼‰

    # 7. æ‰‹åŠ¨è®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒï¼šæ›¿ä»£ Lightning çš„ trainer.fitï¼‰
    print("ğŸš€ å¼€å§‹æ— ç›‘ç£è®­ç»ƒ...")
    print(f"ğŸ“Š è®­ç»ƒé…ç½®ï¼šè®¾å¤‡={device}ï¼Œè½®æ¬¡={max_epochs}ï¼Œæ‰¹å¤§å°={batch_size}")

    for epoch in range(1, max_epochs + 1):
        epoch_start_time = time.time()
        model.train()  # å¼€å¯è®­ç»ƒæ¨¡å¼
        total_loss = 0.0
        step = 0

        # å•è½®æ¬¡è®­ç»ƒï¼ˆéå†æ‰€æœ‰æ‰¹æ¬¡ï¼‰
        for batch_idx, batch in enumerate(train_loader):
            step += 1
            # å•æ‰¹æ¬¡è®­ç»ƒï¼ˆè°ƒç”¨æ¨¡å‹çš„ train_step æ–¹æ³•ï¼‰
            batch_loss = model.train_step(batch, optimizer)
            total_loss += batch_loss

            # æŒ‰æ­¥è®°å½•æ—¥å¿—ï¼ˆä¸åŸ log_every_n_steps ä¸€è‡´ï¼‰
            if step % log_every_n_steps == 0:
                current_step = (epoch - 1) * len(train_loader) + step
                writer.add_scalar("Train/Batch Loss", batch_loss, current_step)
                print(f"Epoch [{epoch}/{max_epochs}] | Step {step}/{len(train_loader)} | Batch Loss: {batch_loss:.6f}")

        # è®¡ç®—æœ¬è½®å¹³å‡æŸå¤±
        epoch_avg_loss = total_loss / len(train_loader)
        epoch_time = time.time() - epoch_start_time

        # è®°å½•epochçº§æ—¥å¿—
        writer.add_scalar("Train/Epoch Avg Loss", epoch_avg_loss, epoch)
        print(f"\n[Epoch {epoch:03d}/{max_epochs}] "
              f"Train Avg Loss: {epoch_avg_loss:.6f} | "
              f"Time: {epoch_time:.2f}s\n")

        # ä¿å­˜æœ€ä¼˜æƒé‡ï¼ˆæ›¿ä»£ Lightning çš„ ModelCheckpointï¼‰
        if epoch_avg_loss < best_train_loss:
            best_train_loss = epoch_avg_loss
            torch.save(model.state_dict(), best_model_path)
            print(f"ğŸ” æ£€æµ‹åˆ°æ›´ä¼˜æ¨¡å‹ï¼ˆæŸå¤±ä» {best_train_loss:.6f} é™è‡³ {epoch_avg_loss:.6f}ï¼‰ï¼Œå·²ä¿å­˜åˆ°ï¼š{best_model_path}")

    # 8. è®­ç»ƒå®Œæˆåæ¸…ç†
    writer.close()  # å…³é—­TensorBoardæ—¥å¿—
    print("ğŸ¯ è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æœ€ä¼˜æƒé‡ä¿å­˜è·¯å¾„ï¼š{best_model_path}")
    print(f"ğŸ“Š è®­ç»ƒæ—¥å¿—ä¿å­˜è·¯å¾„ï¼š{log_dir}ï¼ˆå¯é€šè¿‡ tensorboard --logdir {log_dir} æŸ¥çœ‹ï¼‰")


if __name__ == "__main__":
    main()